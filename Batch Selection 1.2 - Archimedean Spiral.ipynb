{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from loop import TrainingLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/spirals.csv')\n",
    "X = data.drop('label', axis=1).to_numpy()\n",
    "y = data['label'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(7, activation='sigmoid'))\n",
    "model.add(Dense(7, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.fit(X_train, y_train, batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definign optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 150\n",
    "\n",
    "log_path = 'logs/sorting/archimedean.csv'\n",
    "\n",
    "train_metrics = tf.keras.metrics.BinaryAccuracy()\n",
    "val_metrics = tf.keras.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def calc_loss(x_train, y_train, model, loss_function):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x_train, training=False)\n",
    "        loss_value = loss_function(y_train, logits)\n",
    "    return loss_value\n",
    "\n",
    "length = 5\n",
    "def windowed_batch_selector(data, idx, model, loss_function ):\n",
    "    largest_loss = 0\n",
    "    largest_loss_idx = idx\n",
    "\n",
    "    if idx < len(data) - length:\n",
    "        for i in range(idx, idx+length):\n",
    "            x_batch_train = data[i][0]\n",
    "            y_batch_train = data[i][1]\n",
    "            loss = calc_loss(x_batch_train, y_batch_train, model, loss_function)\n",
    "            if loss > largest_loss:\n",
    "                largest_loss = loss\n",
    "                largest_loss_idx = i\n",
    "        return largest_loss_idx\n",
    "    else:\n",
    "        loss = calc_loss(data[idx][0], data[idx][1], model, loss_function)\n",
    "        return idx\n",
    "\n",
    "\n",
    "losses = []\n",
    "def sorting_batch_selector(data, idx, model, loss_function):\n",
    "    global losses\n",
    "    if idx == 0:\n",
    "        for i in range(len(data)):\n",
    "            x_batch_train = data[i][0]\n",
    "            y_batch_train = data[i][1]\n",
    "            losses.append([i, float(calc_loss(x_batch_train, y_batch_train, model, loss_function))])\n",
    "        losses = sorted(losses, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "\n",
    "    return_idx = losses[idx][0]\n",
    "    if idx == len(data)-1:\n",
    "        losses.clear()\n",
    "    \n",
    "    return return_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\t  0% | 0/45 [00:00<?, ?it/s]WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1/150\tLoss: 0.6765\tMetrics: 0.4416: \tValidation metrics: 0.4375: \t100% | 45/45 [00:00<00:00, 73.51it/s]\n",
      "Epoch 2/150\tLoss: 0.6750\tMetrics: 0.4625: \tValidation metrics: 0.4749: \t100% | 45/45 [00:00<00:00, 392.15it/s]\n",
      "Epoch 3/150\tLoss: 0.6746\tMetrics: 0.4638: \tValidation metrics: 0.4749: \t100% | 45/45 [00:00<00:00, 349.22it/s]\n",
      "Epoch 4/150\tLoss: 0.6737\tMetrics: 0.4722: \tValidation metrics: 0.4749: \t100% | 45/45 [00:00<00:00, 352.87it/s]\n",
      "Epoch 5/150\tLoss: 0.6732\tMetrics: 0.4763: \tValidation metrics: 0.5249: \t100% | 45/45 [00:00<00:00, 273.28it/s]\n",
      "Epoch 6/150\tLoss: 0.6724\tMetrics: 0.4847: \tValidation metrics: 0.5249: \t100% | 45/45 [00:00<00:00, 297.91it/s]\n",
      "Epoch 7/150\tLoss: 0.6718\tMetrics: 0.4986: \tValidation metrics: 0.5249: \t100% | 45/45 [00:00<00:00, 268.68it/s]\n",
      "Epoch 8/150\tLoss: 0.6708\tMetrics: 0.5069: \tValidation metrics: 0.5500: \t100% | 45/45 [00:00<00:00, 305.30it/s]\n",
      "Epoch 9/150\tLoss: 0.6702\tMetrics: 0.5124: \tValidation metrics: 0.5500: \t100% | 45/45 [00:00<00:00, 361.84it/s]\n",
      "Epoch 10/150\tLoss: 0.6691\tMetrics: 0.5291: \tValidation metrics: 0.5625: \t100% | 45/45 [00:00<00:00, 363.59it/s]\n",
      "Epoch 11/150\tLoss: 0.6680\tMetrics: 0.5416: \tValidation metrics: 0.5500: \t100% | 45/45 [00:00<00:00, 269.86it/s]\n",
      "Epoch 12/150\tLoss: 0.6665\tMetrics: 0.5472: \tValidation metrics: 0.5625: \t100% | 45/45 [00:00<00:00, 311.14it/s]\n",
      "Epoch 13/150\tLoss: 0.6649\tMetrics: 0.5555: \tValidation metrics: 0.5874: \t100% | 45/45 [00:00<00:00, 267.83it/s]\n",
      "Epoch 14/150\tLoss: 0.6630\tMetrics: 0.5666: \tValidation metrics: 0.5874: \t100% | 45/45 [00:00<00:00, 315.51it/s]\n",
      "Epoch 15/150\tLoss: 0.6611\tMetrics: 0.5749: \tValidation metrics: 0.6000: \t100% | 45/45 [00:00<00:00, 268.61it/s]\n",
      "Epoch 16/150\tLoss: 0.6588\tMetrics: 0.5888: \tValidation metrics: 0.6125: \t100% | 45/45 [00:00<00:00, 301.62it/s]\n",
      "Epoch 17/150\tLoss: 0.6563\tMetrics: 0.6000: \tValidation metrics: 0.625: \t100% | 45/45 [00:00<00:00, 346.94it/s]\n",
      "Epoch 18/150\tLoss: 0.6535\tMetrics: 0.6097: \tValidation metrics: 0.625: \t100% | 45/45 [00:00<00:00, 303.93it/s]\n",
      "Epoch 19/150\tLoss: 0.6507\tMetrics: 0.6319: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 310.91it/s]\n",
      "Epoch 20/150\tLoss: 0.6466\tMetrics: 0.6777: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 283.62it/s]\n",
      "Epoch 21/150\tLoss: 0.6423\tMetrics: 0.7124: \tValidation metrics: 0.6625: \t100% | 45/45 [00:00<00:00, 306.99it/s]\n",
      "Epoch 22/150\tLoss: 0.6376\tMetrics: 0.7180: \tValidation metrics: 0.6499: \t100% | 45/45 [00:00<00:00, 297.03it/s]\n",
      "Epoch 23/150\tLoss: 0.6326\tMetrics: 0.7222: \tValidation metrics: 0.6499: \t100% | 45/45 [00:00<00:00, 319.60it/s]\n",
      "Epoch 24/150\tLoss: 0.6273\tMetrics: 0.7305: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 297.48it/s]\n",
      "Epoch 25/150\tLoss: 0.6215\tMetrics: 0.7333: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 312.21it/s]\n",
      "Epoch 26/150\tLoss: 0.6152\tMetrics: 0.7375: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 315.12it/s]\n",
      "Epoch 27/150\tLoss: 0.6083\tMetrics: 0.7347: \tValidation metrics: 0.6499: \t100% | 45/45 [00:00<00:00, 294.23it/s]\n",
      "Epoch 28/150\tLoss: 0.6013\tMetrics: 0.7416: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 283.13it/s]\n",
      "Epoch 29/150\tLoss: 0.5940\tMetrics: 0.7444: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 302.48it/s]\n",
      "Epoch 30/150\tLoss: 0.5865\tMetrics: 0.7472: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 307.11it/s]\n",
      "Epoch 31/150\tLoss: 0.5789\tMetrics: 0.7486: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 289.74it/s]\n",
      "Epoch 32/150\tLoss: 0.5712\tMetrics: 0.7486: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 290.92it/s]\n",
      "Epoch 33/150\tLoss: 0.5634\tMetrics: 0.7513: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 293.84it/s]\n",
      "Epoch 34/150\tLoss: 0.5554\tMetrics: 0.7555: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 284.88it/s]\n",
      "Epoch 35/150\tLoss: 0.5474\tMetrics: 0.7569: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 310.73it/s]\n",
      "Epoch 36/150\tLoss: 0.5393\tMetrics: 0.7597: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 291.61it/s]\n",
      "Epoch 37/150\tLoss: 0.5312\tMetrics: 0.7611: \tValidation metrics: 0.6374: \t100% | 45/45 [00:00<00:00, 273.87it/s]\n",
      "Epoch 38/150\tLoss: 0.5231\tMetrics: 0.7624: \tValidation metrics: 0.6499: \t100% | 45/45 [00:00<00:00, 308.15it/s]\n",
      "Epoch 39/150\tLoss: 0.5149\tMetrics: 0.7652: \tValidation metrics: 0.6499: \t100% | 45/45 [00:00<00:00, 284.73it/s]\n",
      "Epoch 40/150\tLoss: 0.5067\tMetrics: 0.7652: \tValidation metrics: 0.6625: \t100% | 45/45 [00:00<00:00, 291.93it/s]\n",
      "Epoch 41/150\tLoss: 0.4984\tMetrics: 0.7666: \tValidation metrics: 0.6625: \t100% | 45/45 [00:00<00:00, 297.48it/s]\n",
      "Epoch 42/150\tLoss: 0.4901\tMetrics: 0.7708: \tValidation metrics: 0.6750: \t100% | 45/45 [00:00<00:00, 270.68it/s]\n",
      "Epoch 43/150\tLoss: 0.4819\tMetrics: 0.7777: \tValidation metrics: 0.6750: \t100% | 45/45 [00:00<00:00, 288.54it/s]\n",
      "Epoch 44/150\tLoss: 0.4736\tMetrics: 0.7777: \tValidation metrics: 0.6750: \t100% | 45/45 [00:00<00:00, 311.24it/s]\n",
      "Epoch 45/150\tLoss: 0.4654\tMetrics: 0.7791: \tValidation metrics: 0.6750: \t100% | 45/45 [00:00<00:00, 319.99it/s]\n",
      "Epoch 46/150\tLoss: 0.4571\tMetrics: 0.7805: \tValidation metrics: 0.6750: \t100% | 45/45 [00:00<00:00, 297.79it/s]\n",
      "Epoch 47/150\tLoss: 0.4489\tMetrics: 0.7819: \tValidation metrics: 0.6875: \t100% | 45/45 [00:00<00:00, 293.53it/s]\n",
      "Epoch 48/150\tLoss: 0.4409\tMetrics: 0.7819: \tValidation metrics: 0.6999: \t100% | 45/45 [00:00<00:00, 296.42it/s]\n",
      "Epoch 49/150\tLoss: 0.4330\tMetrics: 0.7833: \tValidation metrics: 0.6999: \t100% | 45/45 [00:00<00:00, 285.20it/s]\n",
      "Epoch 50/150\tLoss: 0.4252\tMetrics: 0.7875: \tValidation metrics: 0.7124: \t100% | 45/45 [00:00<00:00, 327.94it/s]\n",
      "Epoch 51/150\tLoss: 0.4174\tMetrics: 0.7930: \tValidation metrics: 0.7250: \t100% | 45/45 [00:00<00:00, 309.66it/s]\n",
      "Epoch 52/150\tLoss: 0.4079\tMetrics: 0.8041: \tValidation metrics: 0.7250: \t100% | 45/45 [00:00<00:00, 304.32it/s]\n",
      "Epoch 53/150\tLoss: 0.3985\tMetrics: 0.8152: \tValidation metrics: 0.7250: \t100% | 45/45 [00:00<00:00, 287.85it/s]\n",
      "Epoch 54/150\tLoss: 0.3890\tMetrics: 0.8263: \tValidation metrics: 0.7375: \t100% | 45/45 [00:00<00:00, 284.70it/s]\n",
      "Epoch 55/150\tLoss: 0.3794\tMetrics: 0.8291: \tValidation metrics: 0.75: \t100% | 45/45 [00:00<00:00, 304.64it/s]\n",
      "Epoch 56/150\tLoss: 0.3699\tMetrics: 0.8361: \tValidation metrics: 0.75: \t100% | 45/45 [00:00<00:00, 309.75it/s]\n",
      "Epoch 57/150\tLoss: 0.3603\tMetrics: 0.8402: \tValidation metrics: 0.75: \t100% | 45/45 [00:00<00:00, 316.91it/s]\n",
      "Epoch 58/150\tLoss: 0.3509\tMetrics: 0.8472: \tValidation metrics: 0.75: \t100% | 45/45 [00:00<00:00, 265.98it/s]\n",
      "Epoch 59/150\tLoss: 0.3414\tMetrics: 0.8472: \tValidation metrics: 0.75: \t100% | 45/45 [00:00<00:00, 299.83it/s]\n",
      "Epoch 60/150\tLoss: 0.3320\tMetrics: 0.8458: \tValidation metrics: 0.7749: \t100% | 45/45 [00:00<00:00, 291.64it/s]\n",
      "Epoch 61/150\tLoss: 0.3228\tMetrics: 0.8486: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 293.13it/s]\n",
      "Epoch 62/150\tLoss: 0.3139\tMetrics: 0.8513: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 290.98it/s]\n",
      "Epoch 63/150\tLoss: 0.3050\tMetrics: 0.8527: \tValidation metrics: 0.8125: \t100% | 45/45 [00:00<00:00, 297.03it/s]\n",
      "Epoch 64/150\tLoss: 0.2963\tMetrics: 0.8541: \tValidation metrics: 0.8125: \t100% | 45/45 [00:00<00:00, 304.37it/s]\n",
      "Epoch 65/150\tLoss: 0.2877\tMetrics: 0.8583: \tValidation metrics: 0.8125: \t100% | 45/45 [00:00<00:00, 291.49it/s]\n",
      "Epoch 66/150\tLoss: 0.2793\tMetrics: 0.8583: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 304.70it/s]\n",
      "Epoch 67/150\tLoss: 0.2711\tMetrics: 0.8583: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 262.68it/s]\n",
      "Epoch 68/150\tLoss: 0.2631\tMetrics: 0.8597: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 283.05it/s]\n",
      "Epoch 69/150\tLoss: 0.2554\tMetrics: 0.8611: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 310.74it/s]\n",
      "Epoch 70/150\tLoss: 0.2475\tMetrics: 0.8597: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 300.33it/s]\n",
      "Epoch 71/150\tLoss: 0.2402\tMetrics: 0.8597: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 296.98it/s]\n",
      "Epoch 72/150\tLoss: 0.2332\tMetrics: 0.8583: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 313.20it/s]\n",
      "Epoch 73/150\tLoss: 0.2263\tMetrics: 0.8597: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 287.87it/s]\n",
      "Epoch 74/150\tLoss: 0.2196\tMetrics: 0.8597: \tValidation metrics: 0.7875: \t100% | 45/45 [00:00<00:00, 298.05it/s]\n",
      "Epoch 75/150\tLoss: 0.2131\tMetrics: 0.8625: \tValidation metrics: 0.7875: \t100% | 45/45 [00:00<00:00, 307.71it/s]\n",
      "Epoch 76/150\tLoss: 0.2069\tMetrics: 0.8625: \tValidation metrics: 0.7875: \t100% | 45/45 [00:00<00:00, 307.79it/s]\n",
      "Epoch 77/150\tLoss: 0.2009\tMetrics: 0.8625: \tValidation metrics: 0.7875: \t100% | 45/45 [00:00<00:00, 296.83it/s]\n",
      "Epoch 78/150\tLoss: 0.1951\tMetrics: 0.8638: \tValidation metrics: 0.7875: \t100% | 45/45 [00:00<00:00, 298.93it/s]\n",
      "Epoch 79/150\tLoss: 0.1896\tMetrics: 0.8638: \tValidation metrics: 0.7875: \t100% | 45/45 [00:00<00:00, 306.15it/s]\n",
      "Epoch 80/150\tLoss: 0.1844\tMetrics: 0.8652: \tValidation metrics: 0.7875: \t100% | 45/45 [00:00<00:00, 296.35it/s]\n",
      "Epoch 81/150\tLoss: 0.1795\tMetrics: 0.8666: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 307.65it/s]\n",
      "Epoch 82/150\tLoss: 0.1746\tMetrics: 0.8708: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 303.62it/s]\n",
      "Epoch 83/150\tLoss: 0.1699\tMetrics: 0.875: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 305.91it/s]\n",
      "Epoch 84/150\tLoss: 0.1653\tMetrics: 0.8777: \tValidation metrics: 0.8000: \t100% | 45/45 [00:00<00:00, 301.40it/s]\n",
      "Epoch 85/150\tLoss: 0.1610\tMetrics: 0.8763: \tValidation metrics: 0.8249: \t100% | 45/45 [00:00<00:00, 306.49it/s]\n",
      "Epoch 86/150\tLoss: 0.1569\tMetrics: 0.8763: \tValidation metrics: 0.8249: \t100% | 45/45 [00:00<00:00, 303.31it/s]\n",
      "Epoch 87/150\tLoss: 0.1531\tMetrics: 0.8763: \tValidation metrics: 0.8374: \t100% | 45/45 [00:00<00:00, 256.88it/s]\n",
      "Epoch 88/150\tLoss: 0.1493\tMetrics: 0.8791: \tValidation metrics: 0.8374: \t100% | 45/45 [00:00<00:00, 300.51it/s]\n",
      "Epoch 89/150\tLoss: 0.1456\tMetrics: 0.8777: \tValidation metrics: 0.8374: \t100% | 45/45 [00:00<00:00, 311.47it/s]\n",
      "Epoch 90/150\tLoss: 0.1420\tMetrics: 0.8819: \tValidation metrics: 0.8374: \t100% | 45/45 [00:00<00:00, 302.16it/s]\n",
      "Epoch 91/150\tLoss: 0.1386\tMetrics: 0.8847: \tValidation metrics: 0.8374: \t100% | 45/45 [00:00<00:00, 288.04it/s]\n",
      "Epoch 92/150\tLoss: 0.1353\tMetrics: 0.8861: \tValidation metrics: 0.8374: \t100% | 45/45 [00:00<00:00, 308.73it/s]\n",
      "Epoch 93/150\tLoss: 0.1322\tMetrics: 0.8861: \tValidation metrics: 0.8374: \t100% | 45/45 [00:00<00:00, 301.73it/s]\n",
      "Epoch 94/150\tLoss: 0.1291\tMetrics: 0.8874: \tValidation metrics: 0.8249: \t100% | 45/45 [00:00<00:00, 307.30it/s]\n",
      "Epoch 95/150\tLoss: 0.1261\tMetrics: 0.8902: \tValidation metrics: 0.8374: \t100% | 45/45 [00:00<00:00, 313.18it/s]\n",
      "Epoch 96/150\tLoss: 0.1232\tMetrics: 0.8916: \tValidation metrics: 0.8374: \t100% | 45/45 [00:00<00:00, 300.28it/s]\n",
      "Epoch 97/150\tLoss: 0.1204\tMetrics: 0.8916: \tValidation metrics: 0.8500: \t100% | 45/45 [00:00<00:00, 294.07it/s]\n",
      "Epoch 98/150\tLoss: 0.1175\tMetrics: 0.8944: \tValidation metrics: 0.8500: \t100% | 45/45 [00:00<00:00, 313.21it/s]\n",
      "Epoch 99/150\tLoss: 0.1149\tMetrics: 0.8972: \tValidation metrics: 0.8500: \t100% | 45/45 [00:00<00:00, 311.29it/s]\n",
      "Epoch 100/150\tLoss: 0.1124\tMetrics: 0.8986: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 297.16it/s]\n",
      "Epoch 101/150\tLoss: 0.1098\tMetrics: 0.8999: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 306.60it/s]\n",
      "Epoch 102/150\tLoss: 0.1072\tMetrics: 0.9069: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 313.62it/s]\n",
      "Epoch 103/150\tLoss: 0.1048\tMetrics: 0.9138: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 310.13it/s]\n",
      "Epoch 104/150\tLoss: 0.1024\tMetrics: 0.9166: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 302.11it/s]\n",
      "Epoch 105/150\tLoss: 0.1000\tMetrics: 0.9166: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 301.30it/s]\n",
      "Epoch 106/150\tLoss: 0.0977\tMetrics: 0.9208: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 313.50it/s]\n",
      "Epoch 107/150\tLoss: 0.0955\tMetrics: 0.9236: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 323.53it/s]\n",
      "Epoch 108/150\tLoss: 0.0933\tMetrics: 0.9236: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 320.11it/s]\n",
      "Epoch 109/150\tLoss: 0.0912\tMetrics: 0.9250: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 340.92it/s]\n",
      "Epoch 110/150\tLoss: 0.0892\tMetrics: 0.9263: \tValidation metrics: 0.8625: \t100% | 45/45 [00:00<00:00, 312.69it/s]\n",
      "Epoch 111/150\tLoss: 0.0873\tMetrics: 0.9291: \tValidation metrics: 0.875: \t100% | 45/45 [00:00<00:00, 310.87it/s]\n",
      "Epoch 112/150\tLoss: 0.0855\tMetrics: 0.9305: \tValidation metrics: 0.875: \t100% | 45/45 [00:00<00:00, 308.63it/s]\n",
      "Epoch 113/150\tLoss: 0.0837\tMetrics: 0.9305: \tValidation metrics: 0.875: \t100% | 45/45 [00:00<00:00, 314.54it/s]\n",
      "Epoch 114/150\tLoss: 0.0820\tMetrics: 0.9319: \tValidation metrics: 0.875: \t100% | 45/45 [00:00<00:00, 306.49it/s]\n",
      "Epoch 115/150\tLoss: 0.0804\tMetrics: 0.9319: \tValidation metrics: 0.875: \t100% | 45/45 [00:00<00:00, 332.64it/s]\n",
      "Epoch 116/150\tLoss: 0.0788\tMetrics: 0.9361: \tValidation metrics: 0.875: \t100% | 45/45 [00:00<00:00, 323.91it/s]\n",
      "Epoch 117/150\tLoss: 0.0773\tMetrics: 0.9375: \tValidation metrics: 0.875: \t100% | 45/45 [00:00<00:00, 316.94it/s]\n",
      "Epoch 118/150\tLoss: 0.0759\tMetrics: 0.9402: \tValidation metrics: 0.875: \t100% | 45/45 [00:00<00:00, 316.18it/s]\n",
      "Epoch 119/150\tLoss: 0.0745\tMetrics: 0.9402: \tValidation metrics: 0.8999: \t100% | 45/45 [00:00<00:00, 326.39it/s]\n",
      "Epoch 120/150\tLoss: 0.0732\tMetrics: 0.9402: \tValidation metrics: 0.8999: \t100% | 45/45 [00:00<00:00, 266.09it/s]\n",
      "Epoch 121/150\tLoss: 0.0720\tMetrics: 0.9416: \tValidation metrics: 0.8999: \t100% | 45/45 [00:00<00:00, 337.78it/s]\n",
      "Epoch 122/150\tLoss: 0.0707\tMetrics: 0.9430: \tValidation metrics: 0.8999: \t100% | 45/45 [00:00<00:00, 347.68it/s]\n",
      "Epoch 123/150\tLoss: 0.0695\tMetrics: 0.9444: \tValidation metrics: 0.8999: \t100% | 45/45 [00:00<00:00, 372.91it/s]\n",
      "Epoch 124/150\tLoss: 0.0684\tMetrics: 0.9472: \tValidation metrics: 0.9125: \t100% | 45/45 [00:00<00:00, 359.99it/s]\n",
      "Epoch 125/150\tLoss: 0.0673\tMetrics: 0.9499: \tValidation metrics: 0.9125: \t100% | 45/45 [00:00<00:00, 362.49it/s]\n",
      "Epoch 126/150\tLoss: 0.0662\tMetrics: 0.9527: \tValidation metrics: 0.9125: \t100% | 45/45 [00:00<00:00, 322.77it/s]\n",
      "Epoch 127/150\tLoss: 0.0652\tMetrics: 0.9527: \tValidation metrics: 0.9125: \t100% | 45/45 [00:00<00:00, 309.92it/s]\n",
      "Epoch 128/150\tLoss: 0.0641\tMetrics: 0.9527: \tValidation metrics: 0.9125: \t100% | 45/45 [00:00<00:00, 334.54it/s]\n",
      "Epoch 129/150\tLoss: 0.0631\tMetrics: 0.9527: \tValidation metrics: 0.9125: \t100% | 45/45 [00:00<00:00, 334.83it/s]\n",
      "Epoch 130/150\tLoss: 0.0620\tMetrics: 0.9527: \tValidation metrics: 0.9250: \t100% | 45/45 [00:00<00:00, 357.63it/s]\n",
      "Epoch 131/150\tLoss: 0.0610\tMetrics: 0.9541: \tValidation metrics: 0.9250: \t100% | 45/45 [00:00<00:00, 326.66it/s]\n",
      "Epoch 132/150\tLoss: 0.0600\tMetrics: 0.9541: \tValidation metrics: 0.9250: \t100% | 45/45 [00:00<00:00, 320.93it/s]\n",
      "Epoch 133/150\tLoss: 0.0590\tMetrics: 0.9541: \tValidation metrics: 0.9250: \t100% | 45/45 [00:00<00:00, 283.65it/s]\n",
      "Epoch 134/150\tLoss: 0.0581\tMetrics: 0.9541: \tValidation metrics: 0.9250: \t100% | 45/45 [00:00<00:00, 329.84it/s]\n",
      "Epoch 135/150\tLoss: 0.0572\tMetrics: 0.9541: \tValidation metrics: 0.9250: \t100% | 45/45 [00:00<00:00, 295.73it/s]\n",
      "Epoch 136/150\tLoss: 0.0562\tMetrics: 0.9555: \tValidation metrics: 0.9250: \t100% | 45/45 [00:00<00:00, 347.15it/s]\n",
      "Epoch 137/150\tLoss: 0.0553\tMetrics: 0.9555: \tValidation metrics: 0.9250: \t100% | 45/45 [00:00<00:00, 293.64it/s]\n",
      "Epoch 138/150\tLoss: 0.0544\tMetrics: 0.9555: \tValidation metrics: 0.9250: \t100% | 45/45 [00:00<00:00, 305.67it/s]\n",
      "Epoch 139/150\tLoss: 0.0535\tMetrics: 0.9555: \tValidation metrics: 0.9375: \t100% | 45/45 [00:00<00:00, 300.27it/s]\n",
      "Epoch 140/150\tLoss: 0.0526\tMetrics: 0.9555: \tValidation metrics: 0.9375: \t100% | 45/45 [00:00<00:00, 297.70it/s]\n",
      "Epoch 141/150\tLoss: 0.0517\tMetrics: 0.9583: \tValidation metrics: 0.9375: \t100% | 45/45 [00:00<00:00, 316.13it/s]\n",
      "Epoch 142/150\tLoss: 0.0498\tMetrics: 0.9597: \tValidation metrics: 0.9499: \t100% | 45/45 [00:00<00:00, 332.06it/s]\n",
      "Epoch 143/150\tLoss: 0.0484\tMetrics: 0.9597: \tValidation metrics: 0.9499: \t100% | 45/45 [00:00<00:00, 373.95it/s]\n",
      "Epoch 144/150\tLoss: 0.0470\tMetrics: 0.9611: \tValidation metrics: 0.9499: \t100% | 45/45 [00:00<00:00, 383.15it/s]\n",
      "Epoch 145/150\tLoss: 0.0457\tMetrics: 0.9611: \tValidation metrics: 0.9499: \t100% | 45/45 [00:00<00:00, 367.92it/s]\n",
      "Epoch 146/150\tLoss: 0.0444\tMetrics: 0.9624: \tValidation metrics: 0.9499: \t100% | 45/45 [00:00<00:00, 356.64it/s]\n",
      "Epoch 147/150\tLoss: 0.0431\tMetrics: 0.9638: \tValidation metrics: 0.9499: \t100% | 45/45 [00:00<00:00, 329.50it/s]\n",
      "Epoch 148/150\tLoss: 0.0419\tMetrics: 0.9638: \tValidation metrics: 0.9499: \t100% | 45/45 [00:00<00:00, 305.96it/s]\n",
      "Epoch 149/150\tLoss: 0.0408\tMetrics: 0.9652: \tValidation metrics: 0.9499: \t100% | 45/45 [00:00<00:00, 299.54it/s]\n",
      "Epoch 150/150\tLoss: 0.0396\tMetrics: 0.9652: \tValidation metrics: 0.9499: \t100% | 45/45 [00:00<00:00, 366.88it/s]\n"
     ]
    }
   ],
   "source": [
    "training = TrainingLoop(model, X_train, y_train, \n",
    "                        loss_function, optimizer,\n",
    "                        train_metrics,\n",
    "                        val_metrics, \n",
    "                        validation_split=0.1, \n",
    "                        batch_size=batch_size, \n",
    "                        batch_selection=sorting_batch_selector, \n",
    "                        log_file=log_path)\n",
    "\n",
    "training.train(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}