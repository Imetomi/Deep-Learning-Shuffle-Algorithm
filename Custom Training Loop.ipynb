{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.6 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "f0b7ef81dbfba64741f51278088cbb108f5f8bdb279b68750dee812d0a6f384d"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6-final"
    },
    "colab": {
      "name": "Custom Training Loop copy.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-jAu6v10cCI"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Both MNIST and Fashion-MNIST can be loaded from Keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tqdm.autonotebook import tqdm, trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdmoP7D_0cCK"
      },
      "source": [
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Convert image pixels to floats between 0 and 1\n",
        "X_train = x_train / 255\n",
        "X_test = x_test / 255\n",
        "\n",
        "# Convert output to one hot encoding\n",
        "Y_train = to_categorical(y_train, 10) \n",
        "Y_test = to_categorical(y_test, 10)\n",
        "\n",
        "X_train = np.expand_dims(X_train, -1)\n",
        "X_test = np.expand_dims(X_test, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frJ-kxzu5X0M"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTmYjsNH0cCK"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Input(shape = (28, 28, 1,)))\n",
        "model.add(layers.Conv2D(32, kernel_size = (3, 3), activation = \"relu\"))\n",
        "model.add(layers.MaxPooling2D( pool_size = (2, 2)))\n",
        "model.add(layers.Conv2D(64, kernel_size = (3, 3), activation = \"relu\"))\n",
        "model.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "print( model.summary() )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOVLq9f10cCM"
      },
      "source": [
        "optimizer = keras.optimizers.Adam()\n",
        "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
        "validation_dataset = validation_dataset.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2RCVhcP0cCQ"
      },
      "source": [
        "train_data = list(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c19ykuh0cCQ"
      },
      "source": [
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRGEFBLB0cCQ"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0vJTm1e0cCR"
      },
      "source": [
        "@tf.function\n",
        "def validation_step(x_val, y_val):\n",
        "    val_logits = model(x_val, training=False)\n",
        "    val_acc_metric.update_state(y_val, val_logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "EcMxjCH90cCR"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):    \n",
        "    steps = trange(len(train_data), bar_format=\"{desc}\\t{percentage:3.0f}% {r_bar}\")\n",
        "    for i in steps:\n",
        "        step = i\n",
        "        x_batch_train = train_data[i][0]\n",
        "        y_batch_train = train_data[i][1]\n",
        "        \n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "        \n",
        "        steps.set_description(\"Epoch \" + str(epoch+1) + '/' + str(epochs) + \"\\tLoss: \" + str(float(loss_value))[:6]\n",
        "                              + \"\\tAccuracy: \" + str(float(train_acc_metric.result()))[:6])\n",
        "        \n",
        "        if i == len(train_data)-1:\n",
        "          \n",
        "            for x_batch_val, y_batch_val in validation_dataset:\n",
        "                validation_step(x_batch_val, y_batch_val)\n",
        "\n",
        "            steps.set_description(steps.desc + \"\\tValidation accuracy: \" + str(float(val_acc_metric.result()))[:6])\n",
        "\n",
        "    train_acc_metric.reset_states()\n",
        "    val_acc_metric.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azSvxFEQKWfm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}