{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Both MNIST and Fashion-MNIST can be loaded from Keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.autonotebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Convert image pixels to floats between 0 and 1\n",
    "X_train = x_train / 255\n",
    "X_test = x_test / 255\n",
    "\n",
    "# Convert output to one hot encoding\n",
    "Y_train = to_categorical(y_train, 10) \n",
    "Y_test = to_categorical(y_test, 10)\n",
    "\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape = (28, 28, 1,)))\n",
    "model.add(layers.Conv2D(32, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(layers.MaxPooling2D( pool_size = (2, 2)))\n",
    "model.add(layers.Conv2D(64, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "#print( model.summary() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_metric = keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits )\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1/20\tLoss: 1.5685\tAccuracy: 0.8956: \t100% | 937/937 [00:02<00:00, 408.89it/s]\n",
      "Epoch 2/20\tLoss: 1.5662\tAccuracy: 0.8971: \t100% | 937/937 [00:02<00:00, 417.66it/s]\n",
      "Epoch 3/20\tLoss: 1.5704\tAccuracy: 0.8986: \t100% | 937/937 [00:02<00:00, 412.22it/s]\n",
      "Epoch 4/20\tLoss: 1.5850\tAccuracy: 0.9000: \t100% | 937/937 [00:02<00:00, 416.37it/s]\n",
      "Epoch 5/20\tLoss: 1.5585\tAccuracy: 0.9013: \t100% | 937/937 [00:02<00:00, 413.14it/s]\n",
      "Epoch 6/20\tLoss: 1.5748\tAccuracy: 0.9025: \t100% | 937/937 [00:02<00:00, 420.94it/s]\n",
      "Epoch 7/20\tLoss: 1.5782\tAccuracy: 0.9037: \t100% | 937/937 [00:02<00:00, 422.08it/s]\n",
      "Epoch 8/20\tLoss: 1.5533\tAccuracy: 0.9048: \t100% | 937/937 [00:02<00:00, 426.61it/s]\n",
      "Epoch 9/20\tLoss: 1.5775\tAccuracy: 0.9059: \t100% | 937/937 [00:02<00:00, 420.76it/s]\n",
      "Epoch 10/20\tLoss: 1.5758\tAccuracy: 0.9069: \t100% | 937/937 [00:02<00:00, 415.52it/s]\n",
      "Epoch 11/20\tLoss: 1.5668\tAccuracy: 0.9079: \t100% | 937/937 [00:02<00:00, 416.66it/s]\n",
      "Epoch 12/20\tLoss: 1.5606\tAccuracy: 0.9088: \t100% | 937/937 [00:02<00:00, 413.05it/s]\n",
      "Epoch 13/20\tLoss: 1.5663\tAccuracy: 0.9097: \t100% | 937/937 [00:02<00:00, 416.46it/s]\n",
      "Epoch 14/20\tLoss: 1.5632\tAccuracy: 0.9106: \t100% | 937/937 [00:02<00:00, 410.39it/s]\n",
      "Epoch 15/20\tLoss: 1.5613\tAccuracy: 0.9115: \t100% | 937/937 [00:02<00:00, 415.42it/s]\n",
      "Epoch 16/20\tLoss: 1.5559\tAccuracy: 0.9123: \t100% | 937/937 [00:02<00:00, 416.85it/s]\n",
      "Epoch 17/20\tLoss: 1.5428\tAccuracy: 0.9131: \t100% | 937/937 [00:02<00:00, 408.27it/s]\n",
      "Epoch 18/20\tLoss: 1.5483\tAccuracy: 0.9139: \t100% | 937/937 [00:02<00:00, 370.93it/s]\n",
      "Epoch 19/20\tLoss: 1.5507\tAccuracy: 0.9146: \t100% | 937/937 [00:02<00:00, 410.48it/s]\n",
      "Epoch 20/20\tLoss: 1.5475\tAccuracy: 0.9153: \t100% | 937/937 [00:02<00:00, 409.60it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    steps = trange(len(train_data), bar_format=\"{desc:30}\\t{percentage:3.0f}% {r_bar}\")\n",
    "    for i in steps:\n",
    "        step = i\n",
    "        x_batch_train = train_data[i][0]\n",
    "        y_batch_train = train_data[i][1]\n",
    "        \n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "        \n",
    "        steps.set_description(\"Epoch \" + str(epoch+1) + '/' + str(epochs) + \"\\tLoss: \" + str(float(loss_value))[:6]\n",
    "                              + \"\\tAccuracy: \" + str(float(train_acc_metric.result()))[:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}