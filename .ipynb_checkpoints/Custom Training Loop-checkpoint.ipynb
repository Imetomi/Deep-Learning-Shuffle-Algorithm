{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Both MNIST and Fashion-MNIST can be loaded from Keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Convert image pixels to floats between 0 and 1\n",
    "X_train = x_train / 255\n",
    "X_test = x_test / 255\n",
    "\n",
    "# Convert output to one hot encoding\n",
    "Y_train = to_categorical(y_train, 10) \n",
    "Y_test = to_categorical(y_test, 10)\n",
    "\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape = (28, 28, 1,)))\n",
    "model.add(layers.Conv2D(32, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(layers.MaxPooling2D( pool_size = (2, 2)))\n",
    "model.add(layers.Conv2D(64, kernel_size = (3, 3), activation = \"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "#model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])\n",
    "#print( model.summary() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(from_logits = True)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices( (X_train, Y_train) )\n",
    "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0:\n",
      "Training loss (for one batch) at step 0: 2.3057\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 2.2753\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 2.1261\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.9913\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.9133\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.7557\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.7363\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.8317\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.7368\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.7151\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.7805\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.8380\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.8390\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.8470\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.7562\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.7040\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.6796\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.7039\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.8301\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.6564\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.7449\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.6038\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.6656\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.6480\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.6684\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.6929\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.7456\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.6917\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.6077\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.7205\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.6504\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.6472\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.7455\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.6776\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.7409\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.6378\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.6980\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.7182\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5941\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.7516\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5970\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.6934\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.7393\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.6680\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.6883\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.7187\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.6633\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.7301\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.7386\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.6464\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.7497\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.6319\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.6530\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.6914\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.6119\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.7117\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.7018\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.6715\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.6819\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.6612\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.6394\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.6529\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.5980\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.6572\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.6619\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.6451\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.6834\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.6464\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.6845\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.6272\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.7075\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.6644\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.6566\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.7445\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.6241\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.6217\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.7511\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.6438\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.6397\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.6598\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5689\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.7536\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.6933\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5980\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.6725\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.6472\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.6960\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.6467\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.6770\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.7620\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.6450\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.6202\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.6387\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5839\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 1:\n",
      "Training loss (for one batch) at step 0: 1.6139\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.6826\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.6833\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5986\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.6589\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.6121\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.6536\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.6559\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.6188\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.6728\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.7291\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.7176\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.7037\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.6702\n",
      "Seen so far: 8384 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 140: 1.6021\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.6487\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.6111\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.6371\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.7288\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.6778\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.6622\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.6276\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.5552\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.5767\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.6166\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.6053\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.6334\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.7288\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.7590\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.7081\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5723\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5734\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.6742\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.5723\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.6324\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.6207\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5491\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.6415\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5390\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5903\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.6158\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.6250\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.6805\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.6003\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.6736\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.6333\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.6075\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.6053\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5986\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.6585\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.6100\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.6110\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5593\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5982\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.5988\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.5956\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.6399\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5541\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.5566\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5636\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5593\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.6632\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.6113\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.6490\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5955\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.6156\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.6447\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.6257\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.6073\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.6090\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.5567\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.5902\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5510\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5876\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.6080\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.6071\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5349\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.6762\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.6267\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.6068\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.6267\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.6186\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.5566\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.6311\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.5826\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.5842\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5824\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.5329\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.6300\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5771\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.6344\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5855\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.6181\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.6077\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 2:\n",
      "Training loss (for one batch) at step 0: 1.5474\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.6015\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.6239\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5502\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.6102\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.6292\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5991\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.6161\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.6602\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.6016\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.5545\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.5878\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5385\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.6785\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5868\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.6383\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.6200\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.6322\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.6015\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.5994\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.6050\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5662\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.6357\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.5839\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.6374\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.6668\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.5999\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.6600\n",
      "Seen so far: 17344 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 280: 1.5306\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.6190\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5498\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.6306\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.6523\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.6048\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5606\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.6225\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5884\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5775\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.6418\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5775\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5482\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5808\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5688\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.6056\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.5223\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5930\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.5567\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5658\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5876\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.7019\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.6634\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.6539\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.6332\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5518\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.6288\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.6338\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.5635\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5440\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.6221\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5860\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5881\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.6012\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.6042\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5783\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.6483\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.6002\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5619\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.6770\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.6045\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5855\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.6320\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.6618\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5827\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5102\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.7069\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5903\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5917\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.5731\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.6015\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.5839\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5574\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5827\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.6531\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.6490\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.5111\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.5496\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5328\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.6124\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5830\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5959\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5147\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5972\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.6479\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5873\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 3:\n",
      "Training loss (for one batch) at step 0: 1.5368\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.6242\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.5905\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5380\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.6247\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5939\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5547\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.6080\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.6016\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.5553\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.6364\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.6260\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5904\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.5132\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5973\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5410\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.6094\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.5846\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.6427\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.6296\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.6405\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5866\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.5944\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.5766\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.6316\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.6008\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.5523\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5711\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.5791\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5970\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5316\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5989\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.6052\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.5702\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.6164\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.6345\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.6264\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.6101\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5129\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5763\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5688\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5368\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5263\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.5430\n",
      "Seen so far: 27584 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 440: 1.6283\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5393\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.6406\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.6057\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5631\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.6066\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.6153\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.6029\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5736\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5799\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.6222\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.5671\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.6392\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5384\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.6254\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5384\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5559\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5916\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.5041\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5797\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5711\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.6098\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5952\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5311\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.6576\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5873\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.5730\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.6630\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5833\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5800\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.5162\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.6432\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5807\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.6216\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5452\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.5912\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.6133\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5237\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.6164\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5622\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.6044\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.5835\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5900\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.6301\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5847\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5441\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.6137\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5959\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.6019\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5819\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 4:\n",
      "Training loss (for one batch) at step 0: 1.5457\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.6109\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.5987\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5302\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.6150\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5254\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5365\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.6048\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.6043\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.6965\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.5934\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.6133\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5533\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.6199\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5837\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5720\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.6103\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.5939\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.6133\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.5575\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.6338\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5752\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.6024\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.6151\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.5829\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.6305\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.6570\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.6057\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.5908\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5417\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.6080\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.6785\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.6828\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.6122\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5762\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.5321\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.6088\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5575\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5517\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5946\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.6012\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5553\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5755\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.6278\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.5617\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5477\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.6100\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5548\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5684\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5622\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.6046\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.5986\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5328\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.7342\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.5331\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.5669\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.6202\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5741\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.5871\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.6091\n",
      "Seen so far: 37824 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 600: 1.5144\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5567\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.5341\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5655\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5787\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.5406\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.6042\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.6063\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.6050\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5573\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.6094\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.5629\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5808\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.6006\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.6038\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5752\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5908\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.5084\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5511\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.6181\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5326\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.6070\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.5350\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.6193\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.6777\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.5854\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.6794\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.5556\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.6406\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5348\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5741\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5198\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5941\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.6077\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 5:\n",
      "Training loss (for one batch) at step 0: 1.5676\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.5308\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.5064\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5482\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.6223\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5397\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5554\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.5407\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.5368\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.5773\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.6116\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.5616\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5637\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.5045\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5949\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5907\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.5979\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.5901\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.5634\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.7021\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.5422\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5920\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.5219\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.5575\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.5508\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.6106\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.5154\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5582\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.5767\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5204\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5367\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5932\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.5775\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.5686\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.6113\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.6327\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5808\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5885\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5955\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.6323\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5257\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5770\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5845\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.5381\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.5746\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.6382\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.5993\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5658\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5226\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5686\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.5641\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.4965\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.6447\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5763\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.6342\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.6348\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.6182\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.6152\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.5991\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.6081\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5429\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5446\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.5564\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5495\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5895\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.6571\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5486\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5081\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.5811\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.6611\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.6016\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.6035\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5686\n",
      "Seen so far: 46144 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 730: 1.5669\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.5515\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5586\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5931\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.5472\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5755\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.6087\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5121\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5643\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.5496\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5935\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.7047\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.4950\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5954\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.5634\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5585\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5580\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5640\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5087\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5639\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5387\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 6:\n",
      "Training loss (for one batch) at step 0: 1.5685\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.5785\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.4800\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5830\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.5073\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5832\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5627\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.6033\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.5567\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.5379\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.5759\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.5542\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5585\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.5587\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5651\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5253\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.5666\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.5616\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.5225\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.5485\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.5979\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5831\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.5989\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.6438\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.5916\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.5231\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.5852\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5744\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.6023\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.6311\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.6113\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5547\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.5098\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.5636\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5148\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.5239\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.6099\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5906\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5359\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5205\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5947\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5129\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.6075\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.5774\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.5685\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5755\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.5856\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5206\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5527\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5853\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.5646\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.6892\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5349\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5965\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.5508\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.5643\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.5740\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5845\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.6177\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5915\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5718\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5493\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.5478\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5155\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5806\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.5626\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5705\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5804\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.5763\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5484\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.5894\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.6204\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5968\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5638\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.4818\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5592\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.6044\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.6289\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5337\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.5718\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5122\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5925\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.5459\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5701\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.5598\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.6390\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5313\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.5826\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5730\n",
      "Seen so far: 56384 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 890: 1.5475\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5418\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5815\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5537\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5533\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 7:\n",
      "Training loss (for one batch) at step 0: 1.5497\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.5607\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.5580\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.6511\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.6349\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5511\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5262\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.5585\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.5779\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.5759\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.5548\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.5764\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5153\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.6065\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5232\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5480\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.5618\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.5391\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.5523\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.5807\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.5959\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5980\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.5490\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.5638\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.6206\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.5675\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.6245\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5616\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.5293\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5714\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5662\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5381\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.5856\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.5148\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5624\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.5458\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5045\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5419\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5916\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5771\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5224\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5970\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5798\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.5571\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.6350\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5718\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.5813\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5302\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5697\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5313\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.5459\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.6478\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5763\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5654\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.5659\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.5619\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.6122\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5762\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.5617\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5386\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.6128\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5404\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.5313\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5382\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5958\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.5761\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5220\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5444\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.5304\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5536\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.6211\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.5799\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5238\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5476\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.6041\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5615\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5655\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.6322\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5209\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.6169\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5157\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5539\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.5473\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5633\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.5604\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.6590\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5989\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.4798\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5260\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5229\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5334\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5549\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5577\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5532\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 8:\n",
      "Training loss (for one batch) at step 0: 1.5015\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.5300\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.5491\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5490\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.5800\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5708\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5280\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.5194\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.5557\n",
      "Seen so far: 5184 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 90: 1.5345\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.6093\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.5358\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5979\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.5228\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5517\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.6555\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.4970\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.5279\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.5186\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.5382\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.5473\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5868\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.5869\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.5392\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.5251\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.5549\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.5393\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5300\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.5727\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5461\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5651\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5278\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.5446\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.5883\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5368\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.6247\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5555\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5745\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5521\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5844\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5562\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5920\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5502\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.4935\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.6108\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.6029\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.5920\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5301\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5790\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5889\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.5428\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.5369\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5665\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5763\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.5683\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.5377\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.5369\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5699\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.5733\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5395\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5832\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5878\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.5744\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.6412\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5933\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.5125\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5037\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5210\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.5859\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5601\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.6371\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.5449\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5784\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5337\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.6914\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5624\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5468\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.5787\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5982\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.5530\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5293\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5270\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.5486\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5923\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.5444\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.5531\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5153\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.6074\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5966\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5795\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5214\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5493\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5273\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5820\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 9:\n",
      "Training loss (for one batch) at step 0: 1.5394\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.5541\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.5173\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5608\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.6077\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5482\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5218\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.5721\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.5321\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.5348\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.6598\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.5538\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5608\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.5222\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.6209\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5947\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.5530\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.5397\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.5761\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.5328\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.5532\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5449\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.6245\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.5403\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.6209\n",
      "Seen so far: 15424 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 250: 1.5946\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.5891\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5501\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.5963\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5586\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.4824\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5972\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.5449\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.6177\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5934\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.5664\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5902\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5265\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5623\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5553\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5619\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5322\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5425\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.5529\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.5652\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5505\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.6186\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5636\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5325\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5892\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.5245\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.5378\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5048\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5967\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.5741\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.5546\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.5758\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5508\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.6373\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5196\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5958\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5929\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.5525\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5235\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5577\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.5509\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5231\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5121\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.5369\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5583\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.5837\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.5800\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5449\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5922\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.5718\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5743\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5374\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.5599\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.6046\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.5584\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5251\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5365\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.6626\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5482\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.5777\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.5176\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5879\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.5545\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5763\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5436\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5377\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.6023\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5434\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5567\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 10:\n",
      "Training loss (for one batch) at step 0: 1.5688\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.5528\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.5174\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5246\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.5663\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5644\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5348\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.5891\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.5664\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.5342\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.5711\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.5233\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5720\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.5435\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5643\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5329\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.5920\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.5670\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.6004\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.5947\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.5775\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5223\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.5100\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.5465\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.6020\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.6407\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.5892\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5507\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.5999\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5792\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5201\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5645\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.5331\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.6287\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5330\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.5257\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5297\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5048\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5803\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.6023\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5202\n",
      "Seen so far: 25664 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 410: 1.4906\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5130\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.6056\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.5671\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5346\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.5889\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5557\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5718\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5684\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.5467\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.5178\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5432\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5192\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.6106\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.5896\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.4976\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5508\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.5376\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5599\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5896\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5854\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.6069\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.6006\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5251\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.6162\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5652\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5577\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.5459\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5443\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.5633\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.4797\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5374\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5599\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.5948\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5617\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5593\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.5784\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5655\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.5516\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5848\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5561\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.5782\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5419\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.5794\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.6113\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5530\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.5852\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5575\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5614\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5652\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5800\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5571\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5229\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 11:\n",
      "Training loss (for one batch) at step 0: 1.5253\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.5551\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.6047\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.6318\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.5716\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5577\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5387\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.5444\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.5662\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.5721\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.5744\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.5639\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5599\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.5477\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5827\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5398\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.5837\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.5967\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.6085\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.5904\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.5141\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5354\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.5498\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.6032\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.5241\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.5363\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.5384\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5665\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.5850\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5610\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5585\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5168\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.5781\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.5145\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5308\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.5469\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5706\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5708\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5327\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5456\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5191\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.4933\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5564\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.5568\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.5364\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5999\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.5279\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5682\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5371\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5177\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.5104\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.5285\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5562\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5480\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.5549\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.5228\n",
      "Seen so far: 35264 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 560: 1.4870\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5324\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.5456\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5242\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5542\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5143\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.5111\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5800\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.6572\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.5507\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5456\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5919\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.5201\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5702\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.5913\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.5547\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5449\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5514\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.5665\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5504\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5812\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.5726\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5819\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.5868\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5108\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5341\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.5433\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5966\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.5189\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.5894\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5993\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.5783\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5126\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5257\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5571\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.6177\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5999\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.4915\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 12:\n",
      "Training loss (for one batch) at step 0: 1.5455\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.5605\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.5698\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5731\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.5255\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5989\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5527\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.5836\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.5268\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.5562\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.5582\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.5578\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5296\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.5405\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5667\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5942\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.5067\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.4939\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.5534\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.5899\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.5633\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5595\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.4928\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.5718\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.5571\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.5035\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.6231\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5514\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.5273\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5110\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5847\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5153\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.5117\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.5506\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5377\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.5185\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5970\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5338\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.4960\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5980\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5410\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5661\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5434\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.5564\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.5901\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5471\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.5243\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5461\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5058\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5309\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.5099\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.4790\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5434\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5841\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.5708\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.4979\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.5512\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5627\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.4753\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5367\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5648\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5450\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.6278\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5588\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.6282\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.5720\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5611\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5554\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.5386\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5263\n",
      "Seen so far: 44224 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 700: 1.6019\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.5137\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5517\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5208\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.5888\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5744\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5231\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.5361\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5563\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.5258\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5736\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.6196\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.5081\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5718\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.5152\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.5578\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5286\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.5520\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5683\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5535\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5534\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5784\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5370\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5300\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 13:\n",
      "Training loss (for one batch) at step 0: 1.5615\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.5136\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.5318\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5337\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.5216\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5731\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5703\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.5731\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.5345\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.6024\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.5310\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.5649\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5620\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.5006\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5512\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5491\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.5191\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.5020\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.5645\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.5371\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.5384\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5527\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.5810\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.5806\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.5557\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.5373\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.5195\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5092\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.5092\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5189\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5767\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5158\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.5626\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.5531\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5122\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.5130\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5458\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.5289\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5292\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5210\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5556\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5263\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.6186\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.5747\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.5646\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5819\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.5223\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.5413\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5081\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5273\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.5153\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.5266\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5420\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5482\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.5600\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.4951\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.4688\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5051\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.5743\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5890\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5720\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5547\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.6139\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5768\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5380\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.5558\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5397\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5074\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.5723\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5814\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.4982\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.5608\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5762\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.5658\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.5444\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5503\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.5970\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.5642\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5325\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.5109\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5160\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5345\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.6198\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5172\n",
      "Seen so far: 53184 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 840: 1.5830\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.5513\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5110\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.6141\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5518\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5294\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5288\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5640\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5749\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5439\n",
      "Seen so far: 59584 samples\n",
      "Epoch - 14:\n",
      "Training loss (for one batch) at step 0: 1.5693\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 10: 1.5614\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 20: 1.5683\n",
      "Seen so far: 1344 samples\n",
      "Training loss (for one batch) at step 30: 1.5995\n",
      "Seen so far: 1984 samples\n",
      "Training loss (for one batch) at step 40: 1.5952\n",
      "Seen so far: 2624 samples\n",
      "Training loss (for one batch) at step 50: 1.5338\n",
      "Seen so far: 3264 samples\n",
      "Training loss (for one batch) at step 60: 1.5649\n",
      "Seen so far: 3904 samples\n",
      "Training loss (for one batch) at step 70: 1.6046\n",
      "Seen so far: 4544 samples\n",
      "Training loss (for one batch) at step 80: 1.5655\n",
      "Seen so far: 5184 samples\n",
      "Training loss (for one batch) at step 90: 1.5466\n",
      "Seen so far: 5824 samples\n",
      "Training loss (for one batch) at step 100: 1.5033\n",
      "Seen so far: 6464 samples\n",
      "Training loss (for one batch) at step 110: 1.6026\n",
      "Seen so far: 7104 samples\n",
      "Training loss (for one batch) at step 120: 1.5035\n",
      "Seen so far: 7744 samples\n",
      "Training loss (for one batch) at step 130: 1.5314\n",
      "Seen so far: 8384 samples\n",
      "Training loss (for one batch) at step 140: 1.5079\n",
      "Seen so far: 9024 samples\n",
      "Training loss (for one batch) at step 150: 1.5481\n",
      "Seen so far: 9664 samples\n",
      "Training loss (for one batch) at step 160: 1.5463\n",
      "Seen so far: 10304 samples\n",
      "Training loss (for one batch) at step 170: 1.4694\n",
      "Seen so far: 10944 samples\n",
      "Training loss (for one batch) at step 180: 1.5067\n",
      "Seen so far: 11584 samples\n",
      "Training loss (for one batch) at step 190: 1.4942\n",
      "Seen so far: 12224 samples\n",
      "Training loss (for one batch) at step 200: 1.5407\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 210: 1.5589\n",
      "Seen so far: 13504 samples\n",
      "Training loss (for one batch) at step 220: 1.5703\n",
      "Seen so far: 14144 samples\n",
      "Training loss (for one batch) at step 230: 1.6384\n",
      "Seen so far: 14784 samples\n",
      "Training loss (for one batch) at step 240: 1.5096\n",
      "Seen so far: 15424 samples\n",
      "Training loss (for one batch) at step 250: 1.5691\n",
      "Seen so far: 16064 samples\n",
      "Training loss (for one batch) at step 260: 1.5497\n",
      "Seen so far: 16704 samples\n",
      "Training loss (for one batch) at step 270: 1.5008\n",
      "Seen so far: 17344 samples\n",
      "Training loss (for one batch) at step 280: 1.6405\n",
      "Seen so far: 17984 samples\n",
      "Training loss (for one batch) at step 290: 1.5415\n",
      "Seen so far: 18624 samples\n",
      "Training loss (for one batch) at step 300: 1.5081\n",
      "Seen so far: 19264 samples\n",
      "Training loss (for one batch) at step 310: 1.5461\n",
      "Seen so far: 19904 samples\n",
      "Training loss (for one batch) at step 320: 1.5158\n",
      "Seen so far: 20544 samples\n",
      "Training loss (for one batch) at step 330: 1.5890\n",
      "Seen so far: 21184 samples\n",
      "Training loss (for one batch) at step 340: 1.5241\n",
      "Seen so far: 21824 samples\n",
      "Training loss (for one batch) at step 350: 1.5470\n",
      "Seen so far: 22464 samples\n",
      "Training loss (for one batch) at step 360: 1.5960\n",
      "Seen so far: 23104 samples\n",
      "Training loss (for one batch) at step 370: 1.4772\n",
      "Seen so far: 23744 samples\n",
      "Training loss (for one batch) at step 380: 1.5631\n",
      "Seen so far: 24384 samples\n",
      "Training loss (for one batch) at step 390: 1.5143\n",
      "Seen so far: 25024 samples\n",
      "Training loss (for one batch) at step 400: 1.5991\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 410: 1.5552\n",
      "Seen so far: 26304 samples\n",
      "Training loss (for one batch) at step 420: 1.5205\n",
      "Seen so far: 26944 samples\n",
      "Training loss (for one batch) at step 430: 1.5330\n",
      "Seen so far: 27584 samples\n",
      "Training loss (for one batch) at step 440: 1.5266\n",
      "Seen so far: 28224 samples\n",
      "Training loss (for one batch) at step 450: 1.5960\n",
      "Seen so far: 28864 samples\n",
      "Training loss (for one batch) at step 460: 1.5066\n",
      "Seen so far: 29504 samples\n",
      "Training loss (for one batch) at step 470: 1.4976\n",
      "Seen so far: 30144 samples\n",
      "Training loss (for one batch) at step 480: 1.5600\n",
      "Seen so far: 30784 samples\n",
      "Training loss (for one batch) at step 490: 1.5370\n",
      "Seen so far: 31424 samples\n",
      "Training loss (for one batch) at step 500: 1.5105\n",
      "Seen so far: 32064 samples\n",
      "Training loss (for one batch) at step 510: 1.5849\n",
      "Seen so far: 32704 samples\n",
      "Training loss (for one batch) at step 520: 1.5411\n",
      "Seen so far: 33344 samples\n",
      "Training loss (for one batch) at step 530: 1.5313\n",
      "Seen so far: 33984 samples\n",
      "Training loss (for one batch) at step 540: 1.5597\n",
      "Seen so far: 34624 samples\n",
      "Training loss (for one batch) at step 550: 1.5648\n",
      "Seen so far: 35264 samples\n",
      "Training loss (for one batch) at step 560: 1.5217\n",
      "Seen so far: 35904 samples\n",
      "Training loss (for one batch) at step 570: 1.5332\n",
      "Seen so far: 36544 samples\n",
      "Training loss (for one batch) at step 580: 1.5613\n",
      "Seen so far: 37184 samples\n",
      "Training loss (for one batch) at step 590: 1.5144\n",
      "Seen so far: 37824 samples\n",
      "Training loss (for one batch) at step 600: 1.5595\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 610: 1.5640\n",
      "Seen so far: 39104 samples\n",
      "Training loss (for one batch) at step 620: 1.5632\n",
      "Seen so far: 39744 samples\n",
      "Training loss (for one batch) at step 630: 1.5864\n",
      "Seen so far: 40384 samples\n",
      "Training loss (for one batch) at step 640: 1.5762\n",
      "Seen so far: 41024 samples\n",
      "Training loss (for one batch) at step 650: 1.5993\n",
      "Seen so far: 41664 samples\n",
      "Training loss (for one batch) at step 660: 1.5603\n",
      "Seen so far: 42304 samples\n",
      "Training loss (for one batch) at step 670: 1.5513\n",
      "Seen so far: 42944 samples\n",
      "Training loss (for one batch) at step 680: 1.5420\n",
      "Seen so far: 43584 samples\n",
      "Training loss (for one batch) at step 690: 1.5450\n",
      "Seen so far: 44224 samples\n",
      "Training loss (for one batch) at step 700: 1.5759\n",
      "Seen so far: 44864 samples\n",
      "Training loss (for one batch) at step 710: 1.5280\n",
      "Seen so far: 45504 samples\n",
      "Training loss (for one batch) at step 720: 1.5216\n",
      "Seen so far: 46144 samples\n",
      "Training loss (for one batch) at step 730: 1.4909\n",
      "Seen so far: 46784 samples\n",
      "Training loss (for one batch) at step 740: 1.5226\n",
      "Seen so far: 47424 samples\n",
      "Training loss (for one batch) at step 750: 1.5313\n",
      "Seen so far: 48064 samples\n",
      "Training loss (for one batch) at step 760: 1.4832\n",
      "Seen so far: 48704 samples\n",
      "Training loss (for one batch) at step 770: 1.5777\n",
      "Seen so far: 49344 samples\n",
      "Training loss (for one batch) at step 780: 1.5646\n",
      "Seen so far: 49984 samples\n",
      "Training loss (for one batch) at step 790: 1.5173\n",
      "Seen so far: 50624 samples\n",
      "Training loss (for one batch) at step 800: 1.5365\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 810: 1.5299\n",
      "Seen so far: 51904 samples\n",
      "Training loss (for one batch) at step 820: 1.5828\n",
      "Seen so far: 52544 samples\n",
      "Training loss (for one batch) at step 830: 1.5875\n",
      "Seen so far: 53184 samples\n",
      "Training loss (for one batch) at step 840: 1.5770\n",
      "Seen so far: 53824 samples\n",
      "Training loss (for one batch) at step 850: 1.5133\n",
      "Seen so far: 54464 samples\n",
      "Training loss (for one batch) at step 860: 1.5561\n",
      "Seen so far: 55104 samples\n",
      "Training loss (for one batch) at step 870: 1.5740\n",
      "Seen so far: 55744 samples\n",
      "Training loss (for one batch) at step 880: 1.5197\n",
      "Seen so far: 56384 samples\n",
      "Training loss (for one batch) at step 890: 1.5254\n",
      "Seen so far: 57024 samples\n",
      "Training loss (for one batch) at step 900: 1.5038\n",
      "Seen so far: 57664 samples\n",
      "Training loss (for one batch) at step 910: 1.5582\n",
      "Seen so far: 58304 samples\n",
      "Training loss (for one batch) at step 920: 1.5543\n",
      "Seen so far: 58944 samples\n",
      "Training loss (for one batch) at step 930: 1.5717\n",
      "Seen so far: 59584 samples\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "for epoch in range( epochs ):\n",
    "    print( \"Epoch - \" + str(epoch) + \":\" )\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training = True )\n",
    "            loss_value = loss_fn( y_batch_train, logits )\n",
    "        \n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        optimizer.apply_gradients( zip( grads, model.trainable_weights ))\n",
    "\n",
    "        if( step % 10 == 0 ):\n",
    "            print( \"Training loss (for one batch) at step %d: %.4f\" % (step, float(loss_value)))\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
