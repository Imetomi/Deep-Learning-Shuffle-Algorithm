{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm as tqdm_n\n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(os.path.join(data_path, 'twitter_train_vectors.npy'), allow_pickle=True)\n",
    "test_data = np.load(os.path.join(data_path, 'twitter_test_vectors.npy'), allow_pickle=True)\n",
    "train_labels = np.load(os.path.join(data_path, 'twitter_train_labels.npy'), allow_pickle=True)\n",
    "test_labels = np.load(os.path.join(data_path, 'twitter_test_labels.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_on_window(data, label, size):\n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    for i in tqdm_n(range(len(data))):\n",
    "        sample = data[i]\n",
    "        if len(sample) >= size:\n",
    "            new_sample = []\n",
    "            count = int(np.floor((len(sample) / size)))\n",
    "            rest = int(len(sample) / size)\n",
    "            for j in range(size-1):\n",
    "                new_sample.append(np.array(sample[j*count:(j+1)*count].mean(axis=0)))\n",
    "            if rest != 0:\n",
    "                new_sample.append(np.array(sample[(size-1)*count:(size)*count+rest].mean(axis=0)))\n",
    "            else:\n",
    "                new_sample.append(np.array(sample[(size-1)*count:(size)*count].mean(axis=0)))\n",
    "            new_data.append(np.array(new_sample))\n",
    "            new_labels.append(label[i])\n",
    "    return np.array(new_data), np.array(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce57fe8a38242bda2e72c828f99de5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = average_on_window(train_data, train_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c38faaac7844858b82d00dc12df4f86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = average_on_window(test_data, test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(10, return_sequences = True, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=True, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=False, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='selu'))\n",
    "model.add(Dense(50, activation='selu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72990 samples, validate on 8111 samples\n",
      "Epoch 1/50\n",
      "72990/72990 [==============================] - 10s 137us/step - loss: 0.6149 - acc: 0.6560 - val_loss: 0.5720 - val_acc: 0.6998\n",
      "Epoch 2/50\n",
      "72990/72990 [==============================] - 9s 123us/step - loss: 0.5498 - acc: 0.7227 - val_loss: 0.5403 - val_acc: 0.7278\n",
      "Epoch 3/50\n",
      "72990/72990 [==============================] - 10s 134us/step - loss: 0.5304 - acc: 0.7367 - val_loss: 0.5292 - val_acc: 0.7374\n",
      "Epoch 4/50\n",
      "72990/72990 [==============================] - 10s 134us/step - loss: 0.5204 - acc: 0.7437 - val_loss: 0.5257 - val_acc: 0.7375\n",
      "Epoch 5/50\n",
      "72990/72990 [==============================] - 10s 140us/step - loss: 0.5142 - acc: 0.7480 - val_loss: 0.5199 - val_acc: 0.7421\n",
      "Epoch 6/50\n",
      "72990/72990 [==============================] - 10s 133us/step - loss: 0.5090 - acc: 0.7517 - val_loss: 0.5183 - val_acc: 0.7463\n",
      "Epoch 7/50\n",
      "72990/72990 [==============================] - 10s 135us/step - loss: 0.5045 - acc: 0.7533 - val_loss: 0.5161 - val_acc: 0.7474\n",
      "Epoch 8/50\n",
      "72990/72990 [==============================] - 10s 138us/step - loss: 0.4995 - acc: 0.7573 - val_loss: 0.5198 - val_acc: 0.7494\n",
      "Epoch 9/50\n",
      "72990/72990 [==============================] - 9s 121us/step - loss: 0.4974 - acc: 0.7590 - val_loss: 0.5127 - val_acc: 0.7482\n",
      "Epoch 10/50\n",
      "72990/72990 [==============================] - 9s 120us/step - loss: 0.4961 - acc: 0.7611 - val_loss: 0.5138 - val_acc: 0.7484\n",
      "Epoch 11/50\n",
      "72990/72990 [==============================] - 9s 121us/step - loss: 0.4910 - acc: 0.7626 - val_loss: 0.5124 - val_acc: 0.7517\n",
      "Epoch 12/50\n",
      "72990/72990 [==============================] - 9s 122us/step - loss: 0.4895 - acc: 0.7634 - val_loss: 0.5168 - val_acc: 0.7498\n",
      "Epoch 13/50\n",
      "72990/72990 [==============================] - 9s 122us/step - loss: 0.4867 - acc: 0.7644 - val_loss: 0.5102 - val_acc: 0.7522\n",
      "Epoch 14/50\n",
      "72990/72990 [==============================] - 9s 127us/step - loss: 0.4849 - acc: 0.7672 - val_loss: 0.5124 - val_acc: 0.7516\n",
      "Epoch 15/50\n",
      "72990/72990 [==============================] - 9s 129us/step - loss: 0.4830 - acc: 0.7673 - val_loss: 0.5130 - val_acc: 0.7524\n",
      "Epoch 16/50\n",
      "72990/72990 [==============================] - 9s 125us/step - loss: 0.4796 - acc: 0.7700 - val_loss: 0.5096 - val_acc: 0.7523\n",
      "Epoch 17/50\n",
      "72990/72990 [==============================] - 9s 124us/step - loss: 0.4766 - acc: 0.7711 - val_loss: 0.5172 - val_acc: 0.7518\n",
      "Epoch 18/50\n",
      "72990/72990 [==============================] - 9s 128us/step - loss: 0.4770 - acc: 0.7714 - val_loss: 0.5103 - val_acc: 0.7553\n",
      "Epoch 19/50\n",
      "72990/72990 [==============================] - 9s 125us/step - loss: 0.4742 - acc: 0.7735 - val_loss: 0.5118 - val_acc: 0.7532\n",
      "Epoch 20/50\n",
      "72990/72990 [==============================] - 9s 121us/step - loss: 0.4716 - acc: 0.7748 - val_loss: 0.5124 - val_acc: 0.7554\n",
      "Epoch 21/50\n",
      "72990/72990 [==============================] - 9s 121us/step - loss: 0.4708 - acc: 0.7753 - val_loss: 0.5159 - val_acc: 0.7537\n",
      "Epoch 22/50\n",
      "72990/72990 [==============================] - 10s 134us/step - loss: 0.4675 - acc: 0.7782 - val_loss: 0.5155 - val_acc: 0.7524\n",
      "Epoch 23/50\n",
      "72990/72990 [==============================] - 10s 134us/step - loss: 0.4660 - acc: 0.7783 - val_loss: 0.5200 - val_acc: 0.7452\n",
      "Epoch 24/50\n",
      "72990/72990 [==============================] - 9s 130us/step - loss: 0.4663 - acc: 0.7771 - val_loss: 0.5133 - val_acc: 0.7518\n",
      "Epoch 25/50\n",
      "72990/72990 [==============================] - 10s 132us/step - loss: 0.4636 - acc: 0.7790 - val_loss: 0.5146 - val_acc: 0.7564\n",
      "Epoch 26/50\n",
      "72990/72990 [==============================] - 10s 133us/step - loss: 0.4627 - acc: 0.7801 - val_loss: 0.5167 - val_acc: 0.7521\n",
      "Epoch 27/50\n",
      "72990/72990 [==============================] - 10s 135us/step - loss: 0.4612 - acc: 0.7808 - val_loss: 0.5146 - val_acc: 0.7496\n",
      "Epoch 28/50\n",
      "72990/72990 [==============================] - 10s 132us/step - loss: 0.4593 - acc: 0.7829 - val_loss: 0.5178 - val_acc: 0.7489\n",
      "Epoch 29/50\n",
      "72990/72990 [==============================] - 10s 135us/step - loss: 0.4586 - acc: 0.7831 - val_loss: 0.5185 - val_acc: 0.7526\n",
      "Epoch 30/50\n",
      "72990/72990 [==============================] - 9s 126us/step - loss: 0.4558 - acc: 0.7851 - val_loss: 0.5212 - val_acc: 0.7527\n",
      "CPU times: user 17min 7s, sys: 1min, total: 18min 7s\n",
      "Wall time: 4min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fac05ac9c10>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, epochs=50, validation_split=0.1, batch_size=1024, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27074/27074 [==============================] - 3s 99us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5207104603963931, 0.749722957611084]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
