{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# needed to avoid a tf error\n",
    "try:\n",
    "    gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading models that we prepared earlier\n",
    "X_train = np.load(os.path.join('data', 'boston', 'boston_train_vectors.npy'), allow_pickle=True)\n",
    "X_test = np.load(os.path.join('data', 'boston', 'boston_test_vectors.npy'), allow_pickle=True)\n",
    "y_train = np.load(os.path.join('data', 'boston', 'boston_train_labels.npy'), allow_pickle=True)\n",
    "y_test = np.load(os.path.join('data', 'boston', 'boston_test_labels.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((404, 13), (404,))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed to get reproducible results\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# building a small model as an experiment\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, activation='sigmoid'))\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='sgd', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping is not used in the current implementation, but we plan to use it in the final model\n",
    "cb = [EarlyStopping(monitor=\"val_mae\", min_delta=0.01, patience=2, verbose=1, \n",
    "                    mode=\"auto\", baseline=None, restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train, batch_size=1, epochs=20, validation_split=0.1, callbacks=cb)"
   ]
  },
  {
   "source": [
    "# Using the custom training loop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing our custom loop\n",
    "from loop import TrainingLoop\n",
    "# importing our batch selection algorithms\n",
    "from batch_selection import windowed_batch_selector, sorting_batch_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SGD oprimizer for training\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "\n",
    "# MSE loss function for this regression task\n",
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 20\n",
    "\n",
    "# using MAE as our secondary metric\n",
    "train_metrics = tf.keras.metrics.MeanAbsoluteError()\n",
    "val_metrics = tf.keras.metrics.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, batch_selector, epochs):\n",
    "    selectors = {windowed_batch_selector: 'windowed', sorting_batch_selector: 'sorting', None: 'original'}\n",
    "    print('\\n\\n'+selectors[batch_selector]+'\\n')\n",
    "    # defining the training class\n",
    "    training = TrainingLoop(model, X_train, y_train, \n",
    "        loss_function, \n",
    "        optimizer, \n",
    "        train_metrics, \n",
    "        val_metrics, \n",
    "        validation_split=0.1, \n",
    "        batch_size=batch_size,\n",
    "        batch_selection=batch_selector,\n",
    "        log_file = os.path.join('logs',selectors[batch_selector],'boston_houses.csv')\n",
    "    )\n",
    "    # training the model\n",
    "    training.train(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    res = model.evaluate(X_test, y_test)\n",
    "    print(np.sqrt(res[0]), res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\t  0% | 0/45 [00:00<?, ?it/s]\n",
      "\n",
      "original\n",
      "\n",
      "WARNING:tensorflow:Layer dense_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1/20\tLoss: 79.287\tMetrics: 7.9209: \tValidation metrics: 6.1495: \t100% | 45/45 [00:03<00:00, 14.69it/s]\n",
      "Epoch 2/20\tLoss: 41.868\tMetrics: 6.5750: \tValidation metrics: 4.6793: \t100% | 45/45 [00:00<00:00, 85.07it/s]\n",
      "Epoch 3/20\tLoss: 20.744\tMetrics: 4.5591: \tValidation metrics: 3.4657: \t100% | 45/45 [00:00<00:00, 75.76it/s]\n",
      "Epoch 4/20\tLoss: 12.836\tMetrics: 3.8331: \tValidation metrics: 3.3674: \t100% | 45/45 [00:00<00:00, 71.20it/s]\n",
      "Epoch 5/20\tLoss: 10.202\tMetrics: 3.7032: \tValidation metrics: 3.1639: \t100% | 45/45 [00:00<00:00, 46.11it/s]\n",
      "Epoch 6/20\tLoss: 8.9491\tMetrics: 3.6084: \tValidation metrics: 3.0296: \t100% | 45/45 [00:00<00:00, 54.75it/s]\n",
      "Epoch 7/20\tLoss: 8.2684\tMetrics: 3.5201: \tValidation metrics: 2.9017: \t100% | 45/45 [00:00<00:00, 56.75it/s]\n",
      "Epoch 8/20\tLoss: 7.9008\tMetrics: 3.4291: \tValidation metrics: 2.8124: \t100% | 45/45 [00:01<00:00, 42.41it/s]\n",
      "Epoch 9/20\tLoss: 7.6462\tMetrics: 3.3461: \tValidation metrics: 2.7227: \t100% | 45/45 [00:01<00:00, 31.40it/s]\n",
      "Epoch 10/20\tLoss: 7.3579\tMetrics: 3.2634: \tValidation metrics: 2.6292: \t100% | 45/45 [00:01<00:00, 40.43it/s]\n",
      "Epoch 11/20\tLoss: 7.0151\tMetrics: 3.1899: \tValidation metrics: 2.5450: \t100% | 45/45 [00:01<00:00, 26.13it/s]\n",
      "Epoch 12/20\tLoss: 6.6562\tMetrics: 3.1233: \tValidation metrics: 2.4765: \t100% | 45/45 [00:01<00:00, 37.66it/s]\n",
      "Epoch 13/20\tLoss: 6.3283\tMetrics: 3.0517: \tValidation metrics: 2.4256: \t100% | 45/45 [00:01<00:00, 41.21it/s]\n",
      "Epoch 14/20\tLoss: 6.0744\tMetrics: 2.9818: \tValidation metrics: 2.3853: \t100% | 45/45 [00:00<00:00, 47.32it/s]\n",
      "Epoch 15/20\tLoss: 5.9009\tMetrics: 2.9195: \tValidation metrics: 2.3589: \t100% | 45/45 [00:00<00:00, 55.15it/s]\n",
      "Epoch 16/20\tLoss: 5.7742\tMetrics: 2.8639: \tValidation metrics: 2.3362: \t100% | 45/45 [00:00<00:00, 55.76it/s]\n",
      "Epoch 17/20\tLoss: 5.6753\tMetrics: 2.8112: \tValidation metrics: 2.3099: \t100% | 45/45 [00:00<00:00, 58.98it/s]\n",
      "Epoch 18/20\tLoss: 5.6109\tMetrics: 2.7613: \tValidation metrics: 2.2852: \t100% | 45/45 [00:00<00:00, 51.49it/s]\n",
      "Epoch 19/20\tLoss: 5.5775\tMetrics: 2.7148: \tValidation metrics: 2.2569: \t100% | 45/45 [00:00<00:00, 57.25it/s]\n",
      "Epoch 20/20\tLoss: 5.5683\tMetrics: 2.6738: \tValidation metrics: 2.2253: \t100% | 45/45 [00:00<00:00, 60.98it/s]\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.1963 - mae: 2.5913\n",
      "4.024466788472549 2.5912773609161377\n",
      "\n",
      "\n",
      "windowed\n",
      "\n",
      "\t  0% | 0/45 [00:00<?, ?it/s]WARNING:tensorflow:Layer dense_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\t  0% | 0/45 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    d:\\BME\\5_felev\\deep_learning\\HF\\Deep-Learning-Shuffle-Algorithm\\batch_selection.py:9 calc_loss  *\n        logits = model(x_train, training=False)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:982 __call__\n        self._maybe_build(inputs)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1171 build\n        self.kernel = self.add_weight(\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:597 add_weight\n        variable = self._add_variable_with_custom_getter(\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:745 _add_variable_with_custom_getter\n        new_variable = getter(\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py:133 make_variable\n        return tf_variables.VariableV1(\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:260 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:206 _variable_v1_call\n        return previous_getter(\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:701 invalid_creator_scope\n        raise ValueError(\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3ce89e8db61b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_selector\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_selector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-ef3131a117dc>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, X_train, y_train, batch_selector, epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m     )\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\BME\\5_felev\\deep_learning\\HF\\Deep-Learning-Shuffle-Algorithm\\loop.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchSelector\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchSelector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLossFunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m                     \u001b[0mx_batch_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                     \u001b[0my_batch_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\BME\\5_felev\\deep_learning\\HF\\Deep-Learning-Shuffle-Algorithm\\batch_selection.py\u001b[0m in \u001b[0;36mwindowed_batch_selector\u001b[1;34m(data, idx, model, loss_function)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mx_batch_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0my_batch_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlargest_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mlargest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    d:\\BME\\5_felev\\deep_learning\\HF\\Deep-Learning-Shuffle-Algorithm\\batch_selection.py:9 calc_loss  *\n        logits = model(x_train, training=False)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:982 __call__\n        self._maybe_build(inputs)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1171 build\n        self.kernel = self.add_weight(\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:597 add_weight\n        variable = self._add_variable_with_custom_getter(\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:745 _add_variable_with_custom_getter\n        new_variable = getter(\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py:133 make_variable\n        return tf_variables.VariableV1(\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:260 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:206 _variable_v1_call\n        return previous_getter(\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    D:\\progs\\python-3.8.6-amd64\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:701 invalid_creator_scope\n        raise ValueError(\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models with different batch selection algorithms.\n",
    "for batch_selector in [None, windowed_batch_selector, sorting_batch_selector]:\n",
    "    # Set random seed so the comparison of different solutions won't be affected by it.\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    model = build_model()\n",
    "    train(model, X_train, y_train, batch_selector=batch_selector, epochs=epochs)\n",
    "    evaluate(model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f0b7ef81dbfba64741f51278088cbb108f5f8bdb279b68750dee812d0a6f384d"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}