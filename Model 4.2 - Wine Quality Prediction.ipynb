{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from loop import TrainingLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(142, 13) (142, 3)\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset from the files saved in the preprocessing notebook.\n",
    "path = 'data/wine'\n",
    "prefix = 'wine_'\n",
    "X_train = np.load(os.path.join(path, prefix+'train_vectors.npy'))\n",
    "y_train = np.load(os.path.join(path, prefix+'train_labels.npy'))\n",
    "X_test  = np.load(os.path.join(path, prefix+'test_vectors.npy'))\n",
    "y_test  = np.load(os.path.join(path, prefix+'test_labels.npy'))\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed so the comparison of different solutions won't be affected by it.\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1/20\tLoss: 1.2288\tMetrics: 0.3083: \tValidation metrics: 0.5: \t100% | 15/15 [00:03<00:00,  4.58it/s]\n",
      "Epoch 2/20\tLoss: 1.0411\tMetrics: 0.3333: \tValidation metrics: 0.5: \t100% | 15/15 [00:00<00:00, 96.16it/s] \n",
      "Epoch 3/20\tLoss: 0.9005\tMetrics: 0.4000: \tValidation metrics: 0.625: \t100% | 15/15 [00:00<00:00, 80.64it/s] \n",
      "Epoch 4/20\tLoss: 0.7932\tMetrics: 0.5416: \tValidation metrics: 0.625: \t100% | 15/15 [00:00<00:00, 77.72it/s]\n",
      "Epoch 5/20\tLoss: 0.6862\tMetrics: 0.6000: \tValidation metrics: 0.75: \t100% | 15/15 [00:00<00:00, 81.97it/s]\n",
      "Epoch 6/20\tLoss: 0.5969\tMetrics: 0.6333: \tValidation metrics: 0.75: \t100% | 15/15 [00:00<00:00, 64.10it/s]\n",
      "Epoch 7/20\tLoss: 0.5225\tMetrics: 0.6499: \tValidation metrics: 0.875: \t100% | 15/15 [00:00<00:00, 86.21it/s] \n",
      "Epoch 8/20\tLoss: 0.4646\tMetrics: 0.6750: \tValidation metrics: 0.875: \t100% | 15/15 [00:00<00:00, 77.72it/s]\n",
      "Epoch 9/20\tLoss: 0.4231\tMetrics: 0.7166: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 90.36it/s] \n",
      "Epoch 10/20\tLoss: 0.3914\tMetrics: 0.7916: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 62.76it/s]\n",
      "Epoch 11/20\tLoss: 0.3658\tMetrics: 0.8000: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 64.66it/s]\n",
      "Epoch 12/20\tLoss: 0.3441\tMetrics: 0.8333: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 66.66it/s]\n",
      "Epoch 13/20\tLoss: 0.3236\tMetrics: 0.8500: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 68.49it/s]\n",
      "Epoch 14/20\tLoss: 0.3004\tMetrics: 0.8666: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 56.60it/s]\n",
      "Epoch 15/20\tLoss: 0.2766\tMetrics: 0.8833: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 46.44it/s]\n",
      "Epoch 16/20\tLoss: 0.2506\tMetrics: 0.9166: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 51.72it/s]\n",
      "Epoch 17/20\tLoss: 0.2231\tMetrics: 0.9333: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 76.92it/s]\n",
      "Epoch 18/20\tLoss: 0.1947\tMetrics: 0.9416: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 34.48it/s]\n",
      "Epoch 19/20\tLoss: 0.1687\tMetrics: 0.9499: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 40.98it/s]\n",
      "Epoch 20/20\tLoss: 0.1456\tMetrics: 0.9666: \tValidation metrics: 1.0: \t100% | 15/15 [00:00<00:00, 74.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Setting up the model.\n",
    "model = Sequential()\n",
    "model.add(Dense(15, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Put the model in our custom training loop.\n",
    "t = TrainingLoop(\n",
    "    model, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_split = 0.1,\n",
    "    batch_size = 8,\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss_function = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    train_metrics = tf.keras.metrics.CategoricalAccuracy(),\n",
    "    val_metrics = tf.keras.metrics.CategoricalAccuracy()\n",
    ")\n",
    "\n",
    "# Traing the model.\n",
    "t.train(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2415 - accuracy: 0.9722\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.24152790009975433, 0.9722222089767456]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# We still have to compile the model for the test evaluation.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# After compiling we can run the evaluation.\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f0b7ef81dbfba64741f51278088cbb108f5f8bdb279b68750dee812d0a6f384d"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}